{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30188.34s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.34.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.25.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"generation.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 19:24:52,110 - INFO - Configuration:\n",
      "2025-04-12 19:24:52,110 - INFO -   Explanation Model: gpt-4o-mini\n",
      "2025-04-12 19:24:52,111 - INFO -   Judge Model: gpt-4o-mini\n",
      "2025-04-12 19:24:52,111 - INFO -   Dataset: GBaker/MedQA-USMLE-4-options\n",
      "2025-04-12 19:24:52,112 - INFO -   Splits: ['train']\n",
      "2025-04-12 19:24:52,112 - INFO -   Output Directory: synthetic_medqa_data\n",
      "2025-04-12 19:24:52,112 - INFO -   Max Samples Per Split: 2\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Configuration\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "SEED = 42\n",
    "EXPLANATION_MODEL = \"gpt-4o-mini\"  \n",
    "DATASET_NAME = \"GBaker/MedQA-USMLE-4-options\"\n",
    "SPLITS_TO_PROCESS = [\"train\"] \n",
    "OUTPUT_DIR = \"synthetic_medqa_data\"\n",
    "MAX_SAMPLES_PER_SPLIT = 2 # Set to a number (e.g., 100) for testing, None to process all\n",
    "\n",
    "# --- Output Format Configuration ---\n",
    "PROMPT_FORMAT = \"\"\"Question: {question}\n",
    "\n",
    "Options:\n",
    "{options_formatted}\n",
    "\n",
    "Choose the best answer and provide a step-by-step explanation for your choice.\"\"\"\n",
    "\n",
    "# How to format the 'chosen' and 'rejected' responses\n",
    "RESPONSE_FORMAT = \"\"\"{answer_label}. {answer_text}\n",
    "Explanation: {explanation}\"\"\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Configuration:\")\n",
    "logger.info(f\"  Explanation Model: {EXPLANATION_MODEL}\")\n",
    "logger.info(f\"  Dataset: {DATASET_NAME}\")\n",
    "logger.info(f\"  Splits: {SPLITS_TO_PROCESS}\")\n",
    "logger.info(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "logger.info(f\"  Max Samples Per Split: {MAX_SAMPLES_PER_SPLIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferencePairGenerator:\n",
    "    def __init__(self, api_key: str, seed: int,\n",
    "                 explanation_model: str,\n",
    "                 prompt_format: str, response_format: str):\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        random.seed(seed)\n",
    "        self.explanation_model = explanation_model\n",
    "        self.prompt_format = prompt_format\n",
    "        self.response_format = response_format\n",
    "        self.label_to_index = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "        self.index_to_label = {v: k for k, v in self.label_to_index.items()}\n",
    "\n",
    "    def call_openai_api(self, messages: List[Dict[str, str]], model: str,\n",
    "                        temperature: float = 0.5, max_tokens: int = 500,\n",
    "                        retry_count: int = 3) -> Optional[Any]:\n",
    "        for attempt in range(retry_count):\n",
    "            try:\n",
    "                return self.client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                time.sleep(2 ** attempt)\n",
    "        logger.error(\"All retry attempts to call OpenAI API have failed.\")\n",
    "        return None\n",
    "\n",
    "    def get_explanation(self, question: str, options_formatted: str, answer: str, is_correct: bool) -> str:\n",
    "        if is_correct:\n",
    "            prompt_detail = (\n",
    "                \"Generate a concise explanation (~20-30 words) highlighting the key clinical reasoning \"\n",
    "                \"and evidence from the vignette that justifies why this answer is the most correct choice.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt_detail = (\n",
    "                \"Pretend this option is correct. Generate a concise explanation (~20-30 words) that appears \"\n",
    "                \"plausible but subtly contains flawed reasoning. Focus on relevant clinical details while \"\n",
    "                \"avoiding any direct mention that this choice might be incorrect.\"\n",
    "            )\n",
    "\n",
    "        prompt = (\n",
    "            f\"Medical Question Context:\\n{question}\\n\\n\"\n",
    "            f\"Options:\\n{options_formatted}\\n\\n\"\n",
    "            f\"Answer Choice to Explain: {answer}\\n\\n\"\n",
    "            f\"{prompt_detail}\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a highly knowledgeable medical expert specializing in clinical reasoning \"\n",
    "                    \"explanations for USMLE-style questions. Be clear, concise, and follow instructions carefully.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = self.call_openai_api(\n",
    "                messages=messages,\n",
    "                model=self.explanation_model,\n",
    "                temperature=0.6,\n",
    "                max_tokens=150\n",
    "            )\n",
    "\n",
    "            if response:\n",
    "                explanation = response.choices[0].message.content.strip()\n",
    "                if not explanation or any(phrase in explanation.lower() for phrase in [\"cannot provide\", \"explanation could not be generated\"]):\n",
    "                    logger.warning(\"Received potentially invalid explanation. Falling back.\")\n",
    "                    return \"[Fallback] Explanation generation failed or returned invalid content.\"\n",
    "                return explanation\n",
    "            else:\n",
    "                return \"[API Error] Explanation could not be generated due to API failure.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating explanation: {e}\")\n",
    "            return \"[Error] An explanation could not be generated.\"\n",
    "\n",
    "    def select_alternative_answer(self, options: List[str], correct_index: int) -> int:\n",
    "        incorrect_indices = [i for i in range(len(options)) if i != correct_index]\n",
    "        return random.choice(incorrect_indices) if incorrect_indices else (correct_index + 1) % len(options)\n",
    "\n",
    "    def process_sample(self, sample: Dict[str, Any], idx: int) -> Optional[Dict[str, Any]]:\n",
    "        try:\n",
    "            question = sample.get(\"question\")\n",
    "            options = sample.get(\"options\")\n",
    "\n",
    "            if not question or not options:\n",
    "                logger.warning(f\"Sample {idx}: Missing question or options. Skipping.\")\n",
    "                return None\n",
    "\n",
    "            correct_label = sample.get(\"answer_idx\").upper()\n",
    "            correct_index = self.label_to_index[correct_label]\n",
    "            correct_option_text = options[correct_label]\n",
    "\n",
    "            options_formatted = \"\\n\".join(\n",
    "                [f\"{self.index_to_label[i]}. {opt}\" for i, opt in enumerate(options.values())]\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Sample {idx}: Generating explanation for CORRECT answer ({correct_label})\")\n",
    "            correct_explanation = self.get_explanation(question, options_formatted, correct_option_text, is_correct=True)\n",
    "            if \"[Error]\" in correct_explanation or \"[API Error]\" in correct_explanation:\n",
    "                logger.error(f\"Sample {idx}: Failed to generate explanation for correct answer. Skipping.\")\n",
    "                return None\n",
    "\n",
    "            alt_index = self.select_alternative_answer(list(options.values()), correct_index)\n",
    "            alt_label = self.index_to_label[alt_index]\n",
    "            alt_option_text = list(options.values())[alt_index]\n",
    "\n",
    "            logger.info(f\"Sample {idx}: Generating explanation for ALTERNATIVE answer ({alt_label})\")\n",
    "            alt_explanation = self.get_explanation(question, options_formatted, alt_option_text, is_correct=False)\n",
    "\n",
    "            prompt_str = self.prompt_format.format(question=question, options_formatted=options_formatted)\n",
    "            chosen_str = self.response_format.format(answer_label=correct_label, answer_text=correct_option_text, explanation=correct_explanation)\n",
    "            rejected_str = self.response_format.format(answer_label=alt_label, answer_text=alt_option_text, explanation=alt_explanation)\n",
    "\n",
    "            return {\n",
    "                \"prompt\": prompt_str,\n",
    "                \"chosen\": chosen_str,\n",
    "                \"rejected\": rejected_str,\n",
    "                \"metadata\": {\n",
    "                    \"original_question\": question,\n",
    "                    \"options\": options,\n",
    "                    \"correct_index\": correct_index,\n",
    "                    \"alternative_index\": alt_index,\n",
    "                    \"correct_label\": correct_label,\n",
    "                    \"alternative_label\": alt_label,\n",
    "                    \"correct_explanation_raw\": correct_explanation,\n",
    "                    \"alternative_explanation_raw\": alt_explanation,\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Critical error processing sample {idx}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def process_dataset(self, dataset_name: str, splits: List[str],\n",
    "                            output_dir: str, max_samples: Optional[int] = None\n",
    "        ) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:\n",
    "            \"\"\"\n",
    "            Load dataset splits, generate SFT and DPO data, and save results.\n",
    "            Results are also returned in a dict for optional in-code use.\n",
    "\n",
    "            Returns:\n",
    "                A dict mapping each split to its SFT and DPO data.\n",
    "            \"\"\"\n",
    "            all_results = {}\n",
    "\n",
    "            for split in splits:\n",
    "                logger.info(f\"--- Processing {split} split ---\")\n",
    "\n",
    "                try:\n",
    "                    dataset = load_dataset(dataset_name, split=split)\n",
    "                    logger.info(f\"Loaded dataset for {split} split.\")\n",
    "\n",
    "                    # Exclude datapoints over 1024 characters\n",
    "                    dataset = dataset.filter(lambda x: len(x[\"question\"]) <= 1024)\n",
    "\n",
    "                    total_samples = len(dataset)\n",
    "                    logger.info(f\"Total samples in {split}: {total_samples}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to load dataset {dataset_name} for split {split}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Prepare lists and file paths\n",
    "                sft_data = []\n",
    "                dpo_data = []\n",
    "                sft_jsonl_path = os.path.join(output_dir, f\"sft_data_{split}.jsonl\")\n",
    "                dpo_jsonl_path = os.path.join(output_dir, f\"dpo_data_{split}.jsonl\")\n",
    "\n",
    "                processed_count = 0\n",
    "                num_to_process = total_samples if max_samples is None else min(max_samples, total_samples)\n",
    "\n",
    "                pbar_desc = f\"Generating {split} data\" + (f\" (max {max_samples})\" if max_samples else \"\")\n",
    "                pbar_total = None if num_to_process is None else num_to_process\n",
    "\n",
    "                # Open files once, then write results line by line inside the loop\n",
    "                try:\n",
    "                    with open(sft_jsonl_path, \"w\", encoding=\"utf-8\") as f_sft, \\\n",
    "                        open(dpo_jsonl_path, \"w\", encoding=\"utf-8\") as f_dpo:\n",
    "\n",
    "                        for idx, sample in enumerate(tqdm(dataset, total=pbar_total, desc=pbar_desc)):\n",
    "                            if max_samples is not None and processed_count >= max_samples:\n",
    "                                logger.info(f\"Reached max_samples limit ({max_samples}) for {split} split.\")\n",
    "                                break\n",
    "\n",
    "                            processed_result = self.process_sample(sample, idx)\n",
    "                            if processed_result:\n",
    "                                # Create the SFT item\n",
    "                                sft_item = {\n",
    "                                    \"prompt\": processed_result[\"prompt\"],\n",
    "                                    \"response\": processed_result[\"chosen\"]\n",
    "                                }\n",
    "                                # Create the DPO item\n",
    "                                dpo_item = {\n",
    "                                    \"prompt\": processed_result[\"prompt\"],\n",
    "                                    \"response\": processed_result[\"chosen\"],\n",
    "                                    \"rejected\": processed_result[\"rejected\"],\n",
    "                                    \"metadata\": processed_result[\"metadata\"]\n",
    "                                }\n",
    "\n",
    "                                # Immediately write SFT item\n",
    "                                f_sft.write(json.dumps(sft_item, ensure_ascii=False) + \"\\n\")\n",
    "                                f_sft.flush()\n",
    "                                # Immediately write DPO item\n",
    "                                f_dpo.write(json.dumps(dpo_item, ensure_ascii=False) + \"\\n\")\n",
    "                                f_dpo.flush()\n",
    "\n",
    "                                # Also store them in memory\n",
    "                                sft_data.append(sft_item)\n",
    "                                dpo_data.append(dpo_item)\n",
    "\n",
    "                                processed_count += 1\n",
    "                            else:\n",
    "                                logger.warning(f\"Sample {idx} skipped due to processing errors.\")\n",
    "\n",
    "                    logger.info(f\"Finished processing {processed_count} samples for {split} split.\")\n",
    "                    logger.info(f\"Saved {len(sft_data)} SFT entries to {sft_jsonl_path}\")\n",
    "                    logger.info(f\"Saved {len(dpo_data)} DPO entries to {dpo_jsonl_path}\")\n",
    "\n",
    "                    # Optionally show a sample entry for sanity check\n",
    "                    if dpo_data:\n",
    "                        logger.info(f\"--- Sample {split} DPO entry ---\")\n",
    "                        logger.info(json.dumps(dpo_data[0], indent=2, ensure_ascii=False))\n",
    "                        logger.info(f\"--- Sample {split} SFT entry ---\")\n",
    "                        logger.info(json.dumps(sft_data[0], indent=2, ensure_ascii=False))\n",
    "\n",
    "                except IOError as e:\n",
    "                    logger.error(f\"Failed to write data for {split} split: {e}\")\n",
    "\n",
    "                # Store the results for this split in the master dictionary\n",
    "                all_results[split] = {\n",
    "                    \"sft\": sft_data,\n",
    "                    \"dpo\": dpo_data\n",
    "                }\n",
    "\n",
    "            return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Instantiation and Execution\n",
    "generator = PreferencePairGenerator(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    seed=SEED,\n",
    "    explanation_model=EXPLANATION_MODEL,\n",
    "    prompt_format=PROMPT_FORMAT,\n",
    "    response_format=RESPONSE_FORMAT\n",
    ")\n",
    "\n",
    "# Run the dataset processing\n",
    "results = generator.process_dataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    splits=SPLITS_TO_PROCESS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_samples=MAX_SAMPLES_PER_SPLIT\n",
    ")\n",
    "\n",
    "# Summary\n",
    "total_sft_pairs = sum(len(data[\"sft\"]) for data in results.values())\n",
    "total_dpo_pairs = sum(len(data[\"dpo\"]) for data in results.values())\n",
    "logger.info(f\"\\n--- Generation Complete ---\")\n",
    "logger.info(f\"Processed splits: {list(results.keys())}\")\n",
    "logger.info(f\"Total SFT pairs generated: {total_sft_pairs}\")\n",
    "logger.info(f\"Total DPO pairs generated: {total_dpo_pairs}\")\n",
    "logger.info(f\"Data saved in directory: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
